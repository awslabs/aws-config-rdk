import argparse
import json
import os
import shutil
import subprocess
import sys
import tempfile

from os import path

# This is the first method to be externalized from rdk.py!

rules_dir = "terraform_rdk_rules"  # All manifests are outputted to this directory so that they can be deployed in a single TF plan/apply


def get_export_parser():
    parser = argparse.ArgumentParser(
        prog="rdk export",
        description="Used to export the Config Rule to terraform file.",
    )
    parser.add_argument(
        "rulename",
        metavar="<rulename>",
        nargs="*",
        help="Rule name(s) to export to a file.",
    )
    parser.add_argument(
        "-s",
        "--rulesets",
        required=False,
        help="comma-delimited list of RuleSet names",
    )
    parser.add_argument(
        "--all",
        "-a",
        action="store_true",
        help="All rules in the working directory will be deployed.",
    )
    parser.add_argument(
        "--custom-code-bucket",
        required=False,
        help="[optional] The code bucket to which you want to upload a copy of your RDK rule. If not specified, will use the default code bucket for the current region",
    )
    parser.add_argument(
        "--lambda-layers",
        required=False,
        help="[optional] Comma-separated list of Lambda Layer ARNs to deploy with your Lambda function(s).",
    )
    parser.add_argument(
        "--lambda-subnets",
        required=False,
        help="[optional] Comma-separated list of Subnets to deploy your Lambda function(s). If specified, you must also specify --lambda-security-groups.",
    )
    parser.add_argument(
        "--lambda-security-groups",
        required=False,
        help="[optional] Comma-separated list of Security Groups to deploy with your Lambda function(s). If specified, you must also specify --lambda-subnets.",
    )
    parser.add_argument(
        "--lambda-timeout",
        required=False,
        default=60,
        help="[optional] Timeout (in seconds) for the lambda function",
        type=str,
    )
    parser.add_argument(
        "--lambda-role-arn",
        required=False,
        help="[optional] Assign existing iam role to lambda functions. If omitted, new lambda role will be created.",
    )
    parser.add_argument(
        "--lambda-role-name",
        required=False,
        help="[optional] Assign existing iam role to lambda functions. If added, will look for a lambda role in the current account with the given name",
    )
    parser.add_argument(
        "--rdklib-layer-arn",
        required=False,
        help="[optional] Lambda Layer ARN that contains the desired rdklib.  Note that Lambda Layers are region-specific.",
    )
    parser.add_argument(
        "-o",
        "--output-version",
        # required=True,
        help="The Terraform version to use when outputting the export",
        choices=["1.x", "1.x_organization"],
        default="1.x",
    )
    parser.add_argument(
        "-f",
        "--format",
        # required=True,
        help="Export Format",
        choices=["terraform"],
        default="terraform",
    )
    parser.add_argument(
        "-g",
        "--generated-lambda-layer",
        required=False,
        action="store_true",
        help="[optional] Forces rdk deploy to use the Python lambda layer generated by rdk init --generate-lambda-layer",
    )
    parser.add_argument(
        "--custom-layer-name",
        required=False,
        help='[optional] To use with --generated-lambda-layer, forces the flag to look for a specific lambda-layer name. If omitted, "rdklib-layer" will be used',
    )
    parser.add_argument(
        "--copy-terraform-module",
        required=False,
        action="store_true",
        help="[optional] Copies the terraform module to the current directory",
    )
    parser.add_argument(
        "--backend-bucket-name",
        required=False,
        help="[optional] The name of the bucket that contains the Terraform backend for this manifest",
    )
    parser.add_argument(
        "--add-provider-manifest",
        required=False,
        action="store_true",
        help="[optional] If specified, will create a providers.tf file using the specified --region argument (or default region)",
    )

    return parser


def package_function_code(rdk_instance, rule_name, params):
    class_name = rdk_instance.__class__.__name__
    my_session = getattr(rdk_instance, f"_{class_name}__get_boto_session")()
    if params["SourceRuntime"] == "java8":
        # Do java build and package.
        print("Running Gradle Build for " + rule_name)
        working_dir = os.path.join(os.getcwd(), rules_dir, rule_name)
        command = ["gradle", "build"]
        subprocess.call(command, cwd=working_dir)

        # set source as distribution zip
        s3_src = os.path.join(
            os.getcwd(),
            rules_dir,
            rule_name,
            "build",
            "distributions",
            rule_name + ".zip",
        )

    else:
        print("Zipping " + rule_name)
        # Remove old zip file if it already exists
        package_file_dst = os.path.join(rule_name, rule_name + ".zip")
        getattr(rdk_instance, f"_{class_name}__delete_package_file")(package_file_dst)

        # zip rule code files and upload to s3 bucket
        s3_src_dir = os.path.join(os.getcwd(), rules_dir, rule_name)
        tmp_src = shutil.make_archive(
            os.path.join(tempfile.gettempdir(), rule_name + rdk_instance.args.region),
            "zip",
            s3_src_dir,
        )
        if not (os.path.exists(package_file_dst)):
            shutil.copy(tmp_src, package_file_dst)
        s3_src = os.path.abspath(package_file_dst)
        getattr(rdk_instance, f"_{class_name}__delete_package_file")(tmp_src)

    s3_dst = "/".join((rule_name, rule_name + ".zip"))

    print("Zipping complete.")

    return s3_dst


def parse_export_args(rdk_instance):
    rdk_instance.args = get_export_parser().parse_args(rdk_instance.args.command_args, rdk_instance.args)

    if bool(rdk_instance.args.lambda_security_groups) != bool(rdk_instance.args.lambda_subnets):
        print("You must specify both lambda-security-groups and lambda-subnets, or neither.")
        sys.exit(1)

    # Check rule names to make sure none are too long.  This is needed to catch Rules created before length constraint was added.
    if rdk_instance.args.rulename:
        for name in rdk_instance.args.rulename:
            if len(name) > 128:
                print(
                    f"Error: Found Rule with name over 128 characters: {name} \n Recreate the Rule with a shorter name."
                )
                sys.exit(1)


def generate_backend_and_provider_manifests(
    rdk_instance,
    backend_file_path="terraform_rdk_rules/backend.tf",
    provider_file_path="terraform_rdk_rules/provider.tf",
):
    # backend
    if rdk_instance.args.backend_bucket_name:
        backend_bucket_name = rdk_instance.args.backend_bucket_name
        print(f"Using provided backend bucket name: {backend_bucket_name}")
        print("Generating backend manifest...")
        os.makedirs(
            backend_file_path.rsplit("/", 1)[0],
            exist_ok=True,
        )
        with open(backend_file_path, "w") as f:
            f.write(
                f"""
terraform {{
  backend "s3" {{
    encrypt = "true"
    bucket  = "{backend_bucket_name}"
    key     = "rdk_modules"
    region  = "{rdk_instance.args.region}"
  }}
}}
"""
            )
    # provider
    if rdk_instance.args.add_provider_manifest:
        provider_region = rdk_instance.args.region
        print(f"Using provided provider region: {provider_region}")
        print("Generating provider manifest...")
        os.makedirs(
            provider_file_path.rsplit("/", 1)[0],
            exist_ok=True,
        )
        with open(provider_file_path, "w") as f:
            f.write(
                f"""
provider "aws" {{
  region = "{provider_region}"
}}
"""
            )


def export(rdk_instance):
    # Construct mangled names for private methods
    class_name = rdk_instance.__class__.__name__

    # Gather CLI args
    rdk_instance.parse_export_args()

    if rdk_instance.args.output_version == "1.x":
        module_name = "rdk_module"
    elif rdk_instance.args.output_version == "1.x_organization":
        module_name = "rdk_organization_module"
    else:
        raise ValueError("Invalid output version specified")

    # get the rule names
    # getattr is used to reference private class names from external modules
    rule_names = getattr(rdk_instance, f"_{class_name}__get_rule_list_for_command")("export")

    # run the export code
    for rule_name in rule_names:
        print(f"Running export of {rule_name}")
        rule_params, _ = getattr(rdk_instance, f"_{class_name}__get_rule_parameters")(rule_name)

        if "SourceIdentifier" in rule_params:
            print(f"Found Managed Rule {rule_name}, Ignored.")
            print("Export supports only Custom Rules.")
            continue

        try:
            source_events = rule_params.get("SourceEvents").split(",")
        except AttributeError:
            source_events = []
        source_periodic = rule_params.get("SourcePeriodic", "")
        combined_input_parameters = rule_params.get("InputParameters", {})

        if "OptionalParameters" in rule_params:
            # Add non-empty optional parameters
            optional_parameters_json = json.loads(rule_params["OptionalParameters"])
            for key, value in optional_parameters_json.items():
                if value:
                    combined_input_parameters.update({key: value})

        print(f"Found Custom Rule {rule_name}.")

        layers = []
        my_session = getattr(rdk_instance, f"_{class_name}__get_boto_session")()
        layers = getattr(rdk_instance, f"_{class_name}__get_lambda_layers")(my_session, rdk_instance.args, rule_params)

        if rdk_instance.args.lambda_layers:
            additional_layers = rdk_instance.args.lambda_layers.split(",")
            layers.extend(additional_layers)

        subnet_ids = []
        security_group_ids = []
        if rdk_instance.args.lambda_security_groups:
            security_group_ids = rdk_instance.args.lambda_security_groups.split(",")

        if rdk_instance.args.lambda_subnets:
            subnet_ids = rdk_instance.args.lambda_subnets.split(",")

        lambda_role_arn = ""
        if rdk_instance.args.lambda_role_arn:
            print("Existing IAM Role provided: " + rdk_instance.args.lambda_role_arn)
            lambda_role_arn = rdk_instance.args.lambda_role_arn

        if rdk_instance.args.custom_code_bucket:
            code_bucket = rdk_instance.args.custom_code_bucket
        else:
            code_bucket = "config-rule-code-bucket-" + rdk_instance.account_id + "-" + rdk_instance.args.region

        my_params = {
            "rule_name": rule_name,
            "rule_lambda_name": getattr(rdk_instance, f"_{class_name}__get_lambda_name")(rule_name, rule_params),
            "source_bucket": code_bucket,
            "source_runtime": getattr(rdk_instance, f"_{class_name}__get_runtime_string")(rule_params),
            "source_events": source_events,
            "source_periodic": source_periodic,
            "source_input_parameters": json.dumps(combined_input_parameters)[1:-1],  # Remove first and last quote chars
            "source_handler": getattr(rdk_instance, f"_{class_name}__get_handler")(rule_name, rule_params),
            "subnet_ids": subnet_ids,
            "security_group_ids": security_group_ids,
            "lambda_layers": layers,
            "lambda_role_arn": lambda_role_arn,
            "lambda_timeout": str(rdk_instance.args.lambda_timeout),
        }
        longest_param_length = max(len(x) for x in my_params.keys() if bool(my_params.get(x, False)))

        # Write out the file with the variable values
        params_file_path = os.path.join(
            os.getcwd(),
            rules_dir,
            f"{rule_name}.tf",
        )
        if rdk_instance.args.backend_bucket_name:
            generate_backend_and_provider_manifests(
                rdk_instance=rdk_instance,
            )
        with open(params_file_path, "w") as f:
            f.write(f'module "{rule_name}" {{\n')
            f.write(f'  {"source".ljust(longest_param_length)} = "./{module_name}"\n')
            for param in my_params.keys():
                if not my_params[param]:
                    continue  # Skip empty values for clarity
                padded_param = param.ljust(longest_param_length)  # Pad to meet TF formatting standards
                if param in [
                    "lambda_layers",
                    "lambda_timeout",
                    "security_group_ids",
                    "source_events",
                    "subnet_ids",
                ]:
                    # these parameters aren't string type and shouldn't be quoted
                    if isinstance(my_params[param], list):
                        # Lists need to be broken out into double-quoted strings
                        f.write(
                            f"  {padded_param} = {('[' + ', '.join(f'"{item}"' for item in my_params[param]) + ']')}\n"
                        )
                    else:
                        f.write(f"  {padded_param} = {my_params[param]}\n")
                else:
                    f.write(f'  {padded_param} = "{my_params[param]}"\n')
            f.write("}\n")

        # If requested, copy the Terraform module to the rule directory
        copy_to_dir = os.path.join(os.getcwd(), rules_dir, module_name)
        module_folder_not_present = not bool(os.path.exists(copy_to_dir) and os.path.isdir(copy_to_dir))
        if rdk_instance.args.copy_terraform_module or module_folder_not_present:
            print(f"Exporting RDK source module {module_name} to current working directory")
            tf_module_dir = os.path.join(
                path.dirname(__file__),
                "template",
                rdk_instance.args.format,
                rdk_instance.args.output_version,
                module_name,
            )
            shutil.copytree(
                tf_module_dir,
                copy_to_dir,
                dirs_exist_ok=True,
            )
        print("Export completed. This generated the .tf files required to deploy this rule.")
